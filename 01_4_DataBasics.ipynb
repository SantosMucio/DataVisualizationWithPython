{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data files and explore their contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a data file\n",
    "\n",
    "We will be working with the NHANES (National Health and Nutrition Examination Survey) data from the 2015-2016 wave. The raw data for this study are available here: [NHANES 2015-2016](https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=2015)\n",
    "\n",
    "As in many large studies, the NHANES data are spread across multiple files.  The NHANES files are stored in SAS transport (.xpt) format. This is a somewhat obscure format, and while Pandas is perfectly capable of reading the NHANES data directly from the .xpt files, accomplishing this task is a more advanced topic than we want to get into here.  Therefore, we have prepared some merged datasets in .csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T05:19:15.796745300Z",
     "start_time": "2023-10-01T05:19:15.752642300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/nhanes_2015_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that we have actually obtained the data the we are expecting, we can display the shape (number of rows and columns) of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T05:19:42.065429200Z",
     "start_time": "2023-10-01T05:19:42.053923300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5735, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on what we see above, the data set being read here has 5735 rows, corresponding to 5735 people in this wave of the NHANES study, and 28 columns, corresponding to 28 variables in this particular dataset.  Note that NHANES collects thousands of variables on each study subject, but here we are working with a reduced file that contains a limited number of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the contents of a data set\n",
    "\n",
    "Pandas has a number of basic ways to understand what is in a data set. For example, above we used the `.shape` method to determine the numbers of rows and columns in a data set. The columns in a Pandas data frame have names, to see the names, use the `.columns` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T05:28:18.560968100Z",
     "start_time": "2023-10-01T05:28:18.553610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SEQN', 'ALQ101', 'ALQ110', 'ALQ130', 'SMQ020', 'RIAGENDR', 'RIDAGEYR',\n",
       "       'RIDRETH1', 'DMDCITZN', 'DMDEDUC2', 'DMDMARTL', 'DMDHHSIZ', 'WTINT2YR',\n",
       "       'SDMVPSU', 'SDMVSTRA', 'INDFMPIR', 'BPXSY1', 'BPXDI1', 'BPXSY2',\n",
       "       'BPXDI2', 'BMXWT', 'BMXHT', 'BMXBMI', 'BMXLEG', 'BMXARML', 'BMXARMC',\n",
       "       'BMXWAIST', 'HIQ210'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These names correspond to variables in the NHANES study. For example, \"SEQN\" is a unique identifier for one person, and \"BMXWT\" is the subject's weight in kilograms (\"BMX\" is the NHANES prefix for body measurements). The variables in the NHANES data set are documented in a set of \"codebooks\" that are available on-line.  The codebooks for the 2015-2016 wave of NHANES can be found at the following link: [Codebooks NHANES 2015-2016](https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=2015)\n",
    "\n",
    "For convenience, direct links to some of the codebooks are included below:\n",
    "\n",
    "- [Demographics codebook](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm)\n",
    "\n",
    "- [Body measures codebook](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BMX_I.htm)\n",
    "\n",
    "- [Blood pressure codebook](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BPX_I.htm)\n",
    "\n",
    "- [Alcohol questionaire codebook](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/ALQ_I.htm)\n",
    "\n",
    "- [Smoking questionaire codebook](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/SMQ_I.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every variable in a Pandas data frame has a data type.  There are many different data types, but most commonly you will encounter floating point values (real numbers), integers, strings (text), and date/time values.  When Pandas reads a text/csv file, it guesses the data types based on what it sees in the first few rows of the data file.  Usually it selects an appropriate type, but occasionally it does not.  To confirm that the data types are consistent with what the variables represent, inspect the `.dtypes` attribute of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T05:43:48.196356100Z",
     "start_time": "2023-10-01T05:43:48.181154400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEQN          int64\n",
       "ALQ101      float64\n",
       "ALQ110      float64\n",
       "ALQ130      float64\n",
       "SMQ020        int64\n",
       "RIAGENDR      int64\n",
       "RIDAGEYR      int64\n",
       "RIDRETH1      int64\n",
       "DMDCITZN    float64\n",
       "DMDEDUC2    float64\n",
       "DMDMARTL    float64\n",
       "DMDHHSIZ      int64\n",
       "WTINT2YR    float64\n",
       "SDMVPSU       int64\n",
       "SDMVSTRA      int64\n",
       "INDFMPIR    float64\n",
       "BPXSY1      float64\n",
       "BPXDI1      float64\n",
       "BPXSY2      float64\n",
       "BPXDI2      float64\n",
       "BMXWT       float64\n",
       "BMXHT       float64\n",
       "BMXBMI      float64\n",
       "BMXLEG      float64\n",
       "BMXARML     float64\n",
       "BMXARMC     float64\n",
       "BMXWAIST    float64\n",
       "HIQ210      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see here, most of the variables have floating point or integer data type. Unlike many data sets, NHANES does not use any text values in its data. For example, while many datasets would use text labels like \"F\" or \"M\" to denote a subject's gender, this information is represented in NHANES with integer codes.  For example, the variable \"RIAGENDR\" contains each subject's gender, with male gender coded as \"1\" and female gender coded as \"2\". The \"RIAGENDR\" variable is part of the demographics component of NHANES, so this coding can be found in the demographics codebook.\n",
    "\n",
    "Variables like \"BMXWT\" which represent a quantitative measurement will typically be stored as floating point data values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing a data set\n",
    "\n",
    "As discussed above, a Pandas data frame is a rectangular data table, in which the rows represent cases and the columns represent variables. One common manipulation of a data frame is to extract the data for one case or for one variable. There are several ways to do this, as shown below.\n",
    "\n",
    "To extract all the values for one variable, the following four approaches are equivalent.  In the next lines of code, we are assigning the data from one column of the data frame into new variables.  The first three approaches access the variable by name (\"DMDEDUC2\" here is an NHANES variable containing a person's educational attainment).  The fourth approach accesses the variable by position (note that \"DMDEDUC2\" is in position `9` of the `df.columns` array shown above, remember that Python counts starting at position zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T05:57:22.376421500Z",
     "start_time": "2023-10-01T05:57:22.362251200Z"
    }
   },
   "outputs": [],
   "source": [
    "a = df['DMDEDUC2']\n",
    "b = df.loc[:, 'DMDEDUC2']\n",
    "c = df.DMDEDUC2\n",
    "d = df.iloc[:, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another reason to slice a variable out of a data frame is so that we can then pass it into a function. For example, we can find the maximum value over all values in a column using any one of the following four lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T05:58:00.313504500Z",
     "start_time": "2023-10-01T05:58:00.298302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "print(a.max())\n",
    "print(b.max())\n",
    "print(c.max())\n",
    "print(d.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every value has a type, and the type information can be obtained using `type()` function.  This can be useful, for example, if you are looking for the documentation associated with some value, but you do not know what the value's type is.\n",
    "\n",
    "Here we see that the variable `df` has type `.DataFrame`, while one column of `df` has type `.Series`. As noted above, a Series is a Pandas data structure for holding a single column (or row) of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T06:00:03.846682Z",
     "start_time": "2023-10-01T06:00:03.832039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df))  # The type of the variable\n",
    "print(type(df.DMDEDUC2))  # The type of one column of the data frame\n",
    "print(type(df.iloc[2, :]))  # The type of one row of the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may also be useful to slice a row (case) out of a data frame. Just as a data frame's columns have names, the rows also have names, which are called the \"index\".  However many data sets do not have meaningful row names, so it is more common to extract a row of a data frame using its position. The `.iloc[]` method slices rows or columns from a data frame by position (counting from 0). The following line of code extracts row 3 from the data set (which is the fourth row, counting from zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T06:02:53.020493600Z",
     "start_time": "2023-10-01T06:02:53.012649500Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df.iloc[3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important data frame manipulation is to extract a contiguous block of rows or columns from the data set.  Below we slice by position, in the first case taking row positions 3 and 4 (counting from 0, which are rows 4 and 5 counting from 1), and in the second case taking columns 2, 3, and 4 (columns 3, 4, 5 if counting from 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T06:03:18.970179900Z",
     "start_time": "2023-10-01T06:03:18.965984200Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df.iloc[3:5, :]\n",
    "z = df.iloc[:, 2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "When reading a dataset using Pandas, there is a set of values including `NA`, `NULL`, and `NaN` that are taken by default to represent a missing value. The full list of default missing value codes is in the `read_csv` [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).  This document also explains how to change the way that `read_csv` decides whether a variable's value is missing.\n",
    "\n",
    "Pandas has functions called `isnull` and `notnull` that can be used to identify where the missing and non-missing values are located in a data frame. Below we use these functions to count the number of missing and non-missing \"DMDEDUC2\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T06:07:14.922202100Z",
     "start_time": "2023-10-01T06:07:14.909616700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n",
      "5474\n"
     ]
    }
   ],
   "source": [
    "print(pd.isnull(df['DMDEDUC2']).sum())\n",
    "print(pd.notnull(df['DMDEDUC2']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aside, note that there may be a variety of distinct forms of missingness in a variable, and in some cases it is important to keep these values distinct. For example, in case of the \"DMDEDUC2\" variable, in addition to the blank or `NA` values that Pandas considers to be missing, three people responded \"don't know\" (code value 9).  In many analyses, the \"don't know\" values will also be treated as missing, but at this point we are considering \"don't know\" to be a distinct category of observed response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Introduction to Libraries and Data Management.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
